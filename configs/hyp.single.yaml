lr0: 0.0001  # initial learning rate (SGD=1E-2, Adam=1E-3)
lrf: 0.01  # final OneCycleLR learning rate (lr0 * lrf)

# Standard learning schedule
lr_factor: 0.5 # factor to reduce lr on plateau

momentum: 0.937  # SGD momentum/Adam beta1
weight_decay: 0.0005  # optimizer weight decay 5e-4
warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.1  # warmup initial bias lr

box: 1.5  # box/coordinate loss gain
obj: 0.1  # obj loss gain (scale with pixels)
obj_pw: 1.0  # cls BCELoss positive_weight
cls: 0.5  # cls loss gain
cls_pw: 1.0  # cls BCELoss positive_weight

anchor_t: 4.0  # anchor-multiple threshold
# anchors: 1  # anchors per output layer (0 to ignore)

# Augmentation 
hsv_h: 0.03 # image HSV-Hue augmentation (fraction)
hsv_s: 0.7 # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # image HSV-Value augmentation (fraction)

degrees: 30.0 # rotation (+/- deg)
translate: 0.2 # 0.2  # image translation (+/- fraction)
scale: 0.2 # 0.5  # image scale (+/- gain)
shear: 0 # 2.0  # image shear (+/- deg)
perspective: 0 # 0.001 # 0.001  # image perspective (+/- fraction), range 0-0.001
blur: 0 # apply gaussian blur to image (probability)
blur_kernel: 5 # gaussian blur kernel size

flipud: False # image flip up-down (probability)
fliplr: False # 0.1  # image flip left-right (probability)

background:  0.5 # probability of applying random background during training
multi_scale: False # 0.25 # apply random scale transformation +/- 50% during training
occlude: 0.3 # probability of adding random objects to images. Use 0 if you want to disable it.

theta: 0.2 # used in objectiveness/confidence loss calculation
alpha: 2 # used in objectiveness/confidence loss calculation

pretrain_epochs: 40 # number of epochs to train keypoint regression before confidence/objectiveness loss kicks in

